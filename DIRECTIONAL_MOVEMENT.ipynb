{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pygame\n",
    "from gymnasium import Env\n",
    "\n",
    "from gymnasium.spaces import Discrete, Dict, Box\n",
    "\n",
    "# from Agents.agent import Agent\n",
    "from Constants.constants import WHITE, RED, BLUE, SCREEN_WIDTH, SCREEN_HEIGHT\n",
    "\n",
    "from Walls.collision_detection import detect_collision\n",
    "from Walls.wall_class import Walls\n",
    "from Walls.Point_Ray import is_ray_blocked\n",
    "\n",
    "from Entities.turret import Turret\n",
    "\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LEVEL_5_WALLS = {\n",
    "    '1': {'x': 200, 'y': 100, 'width': 25, 'height': 100},\n",
    "    '2': {'x': 200, 'y': 400, 'width': 25, 'height': 100},\n",
    "    '3': {'x': 600, 'y': 100, 'width': 25, 'height': 100},\n",
    "    '4': {'x': 600, 'y': 400, 'width': 25, 'height': 100},\n",
    "    '5': {'x': 200, 'y': 100, 'width': 100, 'height': 25},\n",
    "    '6': {'x': 525, 'y': 100, 'width': 100, 'height': 25},\n",
    "    '7': {'x': 200, 'y': 475, 'width': 100, 'height': 25},\n",
    "    '8': {'x': 525, 'y': 475, 'width': 100, 'height': 25},\n",
    "    \"far-left\": {\"x\": -10, \"y\": -10, \"width\": 10, \"height\": SCREEN_HEIGHT + 10},\n",
    "    \"far-right\": {\"x\": SCREEN_WIDTH, \"y\": -10, \"width\": 10, \"height\": SCREEN_HEIGHT + 10},\n",
    "    \"start_top\": {\"x\": -10, \"y\": -10, \"width\": SCREEN_WIDTH + 10, \"height\": 10},\n",
    "    \"finish_bottom\": {\"x\": -10, \"y\": SCREEN_HEIGHT + 10, \"width\": SCREEN_WIDTH, \"height\": 10},\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CastRay:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_cast_ray_angles(self):\n",
    "        start_angle = 0  # 65 degrees to the left\n",
    "        end_angle = 350  # 65 degrees to the right\n",
    "        angle_step = 10  # One ray every 10 degrees\n",
    "        ray_angles = np.arange(start_angle, end_angle + angle_step, angle_step).tolist()\n",
    "        ray_angles = [angle%360 for angle in ray_angles]\n",
    "\n",
    "        return ray_angles\n",
    "\n",
    "    def cast_rays(self, agent, wall_list):\n",
    "        \n",
    "        ray_angles = self.get_cast_ray_angles()\n",
    "        ray_lengths = []\n",
    "        \n",
    "        for ray_angle in ray_angles:\n",
    "            x1, y1 = agent.center\n",
    "            x2, y2 = x1 + 1000 * math.cos(math.radians(ray_angle)), y1 + 1000 * math.sin(math.radians(ray_angle))\n",
    "            lengths = None\n",
    "\n",
    "            for wall in wall_list:\n",
    "                x3, y3 = wall.x, wall.y\n",
    "                x4, y4 = wall.topright[0], wall.bottomright[1]\n",
    "\n",
    "                for side in [(x3, y3, x4, y3), (x4, y3, x4, y4), (x4, y4, x3, y4), (x3, y4, x3, y3)]:\n",
    "                    x5, y5, x6, y6 = side\n",
    "\n",
    "                    denominator = (x1 - x2) * (y5 - y6) - (y1 - y2) * (x5 - x6)\n",
    "\n",
    "                    if denominator == 0:\n",
    "                        continue\n",
    "\n",
    "                    t = ((x1 - x5) * (y5 - y6) - (y1 - y5) * (x5 - x6)) / denominator\n",
    "                    u = -((x1 - x2) * (y1 - y5) - (y1 - y2) * (x1 - x5)) / denominator\n",
    "\n",
    "                    epsilon = 1e-5  # Small epsilon value\n",
    "\n",
    "                    if 0 <= t <= 1 and 0 <= u <= 1:\n",
    "                        intersection_x = x1 + t * (x2 - x1)\n",
    "                        intersection_y = y1 + t * (y2 - y1)\n",
    "\n",
    "                        # Calculate the distance from the ray start to the intersection point\n",
    "                        distance = math.sqrt((intersection_x - x1) ** 2 + (intersection_y - y1) ** 2)\n",
    "\n",
    "                        if lengths is None or distance < lengths:\n",
    "                            lengths = distance\n",
    "                \n",
    "            if lengths is None:\n",
    "                lengths = 1000\n",
    "                \n",
    "            ray_lengths.append(lengths)\n",
    "        return ray_lengths, ray_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, agent_name, agent_index):\n",
    "        # identity\n",
    "        self.index = agent_index\n",
    "        self.agent = agent_name\n",
    "\n",
    "        # additional attributes\n",
    "        self.health = None\n",
    "        self.isHit = False\n",
    "        self.move = True\n",
    "        self.movement_speed = 300\n",
    "\n",
    "        # positional attributes\n",
    "        self.previous_position = np.array([0, 0], dtype=np.float32)\n",
    "        self.current_position = None\n",
    "        self.same_position = False\n",
    "\n",
    "        self.current_step = 0\n",
    "        self.action = None\n",
    "        self.has_grabbed = False\n",
    "\n",
    "        # these are for the angular motion of the agent\n",
    "        self.angle = 0\n",
    "        self.center = 0\n",
    "        self.direction = 0\n",
    "        self.direction_end = 0\n",
    "        self.radius = 15\n",
    "\n",
    "        # this is custom only for the render function\n",
    "        self.draw_direction_end = 0\n",
    "\n",
    "    # for handling what the action does\n",
    "    def agent_action(self, action):\n",
    "        pass\n",
    "\n",
    "    def _get_min_left(self, walls):\n",
    "        min_x = 1000\n",
    "        for wall in walls:\n",
    "            if wall.left < min_x:\n",
    "                min_x = wall.left\n",
    "        return min_x\n",
    "\n",
    "    # for handling all the initial states\n",
    "    def agent_reset(self, width, height):\n",
    "        padding = 30\n",
    "        # updating the initial random position of the agent at 1st\n",
    "        # self.current_position = np.array(\n",
    "        #     [np.random.uniform(30, self._get_min_left(walls)), np.random.uniform(30, height - padding)],\n",
    "        #     dtype=np.float32)\n",
    "\n",
    "        # self.current_position = np.array([40, height/2], dtype=np.float32)\n",
    "\n",
    "        self.current_position = np.array([80, 550], dtype=np.float32)\n",
    "\n",
    "        # updating the initial orientation to 0 degree at 1st\n",
    "        theta = math.radians(self.angle)\n",
    "        magnitude = padding\n",
    "        # this is for the trigonometry function X and Y\n",
    "        dir_vec_x = magnitude * math.cos(theta)\n",
    "        dir_vec_y = magnitude * math.sin(theta)\n",
    "\n",
    "        # adding the direction vector to the center and get an end point for direction\n",
    "        self.direction_end = np.array([self.current_position[0] + dir_vec_x, self.current_position[1] + dir_vec_y],\n",
    "                                      dtype=np.float32)\n",
    "\n",
    "        # this part is only for the render function\n",
    "        self.draw_direction_end = (self.current_position[0] + dir_vec_x, self.current_position[1] + dir_vec_y)\n",
    "        self.center = (int(self.current_position[0]), int(self.current_position[1]))\n",
    "\n",
    "    # updating the direction, line-end according to given angle when called\n",
    "    def get_direction(self):\n",
    "        # as render function demands an int value\n",
    "        center = (int(self.current_position[0]), int(self.current_position[1]))\n",
    "        self.center = center\n",
    "\n",
    "        # the X, Y angular equation\n",
    "        theta = math.radians(self.angle)\n",
    "        magnitude = 30\n",
    "        # here is the X=cos()\n",
    "        directional_vector_x = magnitude * math.cos(theta)\n",
    "        # here is the Y=sin()\n",
    "        directional_vector_y = magnitude * math.sin(theta)\n",
    "\n",
    "        directional_line_end = np.array([center[0] + directional_vector_x, center[1] + directional_vector_y],\n",
    "                                        dtype=np.float32)\n",
    "        self.direction_end = directional_line_end\n",
    "\n",
    "        direction = directional_line_end - center\n",
    "        direction /= np.linalg.norm(direction)\n",
    "        self.direction = direction\n",
    "        self.draw_direction_end = (center[0] + directional_vector_x, center[1] + directional_vector_y)\n",
    "\n",
    "    # for updating the states of the agent when called\n",
    "    def step_update(self, action, speed_factor, range_x, range_y):\n",
    "\n",
    "        # ! if used directional rotational movement\n",
    "        # rotate clockwise\n",
    "        # if action == 0:\n",
    "\n",
    "        #     self.angle += 10\n",
    "        #     self.angle = self.angle % 360\n",
    "        #     # self.get_direction()\n",
    "\n",
    "        # # rotate anti-clockwise\n",
    "        # elif action == 1:\n",
    "        #     self.angle -= 10\n",
    "        #     self.angle = self.angle % 360\n",
    "        #     # self.get_direction()\n",
    "\n",
    "        # # move front\n",
    "        # elif action == 2:\n",
    "\n",
    "        #     self.current_position = self.current_position + self.direction * self.movement_speed * speed_factor\n",
    "        #     # self.get_direction()\n",
    "\n",
    "        # elif action == 3:\n",
    "\n",
    "\n",
    "        # move back\n",
    "        # elif action == 3:\n",
    "        #     self.current_position = self.current_position - self.direction * self.movement_speed\n",
    "            # self.get_direction()\n",
    "\n",
    "        # do nothing / wait\n",
    "        # elif action == 4:\n",
    "        #     pass\n",
    "\n",
    "        movement_speed = self.movement_speed * speed_factor\n",
    "        if action == 0:\n",
    "            self.current_position[0] = self.current_position[0] - self.movement_speed * speed_factor\n",
    "        elif action == 1:\n",
    "            self.current_position[0] = self.current_position[0] + self.movement_speed * speed_factor\n",
    "        elif action == 2:\n",
    "            self.current_position[1] = self.current_position[1] - self.movement_speed * speed_factor\n",
    "        elif action == 3:\n",
    "            self.current_position[1] = self.current_position[1] + self.movement_speed * speed_factor\n",
    "            \n",
    "        self.get_direction()\n",
    "        self.current_position[0] = np.clip(self.current_position[0], 10, range_x-10)\n",
    "        self.current_position[1] = np.clip(self.current_position[1], 10, range_y-10)\n",
    "\n",
    "    # this function returns all the state needed for the observations\n",
    "    # ! can be changed with need for the algorithm\n",
    "    def get_agent_state(self):\n",
    "\n",
    "        agent_state = {\n",
    "            'agent_id': self.index,\n",
    "            'agent_name': self.agent,\n",
    "            'agent_move_speed': self.movement_speed,\n",
    "            'agent_current_position': self.current_position,\n",
    "            'agent_angle': self.angle\n",
    "        }\n",
    "\n",
    "        return agent_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameEnv(Env):\n",
    "    metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\": 300}\n",
    "\n",
    "    def __init__(self, render_mode=None):\n",
    "        super(GameEnv, self).__init__()\n",
    "\n",
    "        # defining the screen dimension for render purpose\n",
    "        self.screen_width = SCREEN_WIDTH\n",
    "        self.screen_height = SCREEN_HEIGHT\n",
    "\n",
    "        assert render_mode is None or render_mode in self.metadata[\"render_modes\"]\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        # self.observation_space = Dict({\n",
    "        #     \"predator_position\": Box(low=np.array([0, 0], dtype=np.float32),\n",
    "        #                              high=np.array([self.screen_width, self.screen_height], dtype=np.float32),\n",
    "        #                              dtype=np.float32),\n",
    "\n",
    "        #     \"bullet_position\": Box(low=np.array([0, 0], dtype=np.float32),\n",
    "        #                            high=np.array([self.screen_width, self.screen_height], dtype=np.float32),\n",
    "        #                            dtype=np.float32),\n",
    "\n",
    "        #     \"target_position\": Box(low=np.array([0, 0], dtype=np.float32),\n",
    "        #                            high=np.array([self.screen_width, self.screen_height], dtype=np.float32),\n",
    "        #                            dtype=np.float32),\n",
    "        # })\n",
    "\n",
    "        self.observation_space = Box(low=np.zeros(42, np.float32), \n",
    "                                    high=np.array([1000 for _ in range(42)], dtype=np.float32), dtype=np.float32)\n",
    "\n",
    "        self.action_space = Discrete(4)\n",
    "\n",
    "        self.total_steps = 0\n",
    "        self.predator_agent = Agent('predator', 0)\n",
    "        self.predator_total_reward = 0\n",
    "        self.cast_ray = CastRay()\n",
    "\n",
    "        self.obs = None\n",
    "\n",
    "        self.start_time = 0\n",
    "        self.animation_time = None\n",
    "        self.total_running_time = 10\n",
    "\n",
    "        self.window = None\n",
    "        self.clock = None\n",
    "\n",
    "        # for the wall initializations\n",
    "        self.wall = Walls(pygame)\n",
    "        self.walls = None\n",
    "\n",
    "        self.turret = Turret(SCREEN_WIDTH, SCREEN_HEIGHT)\n",
    "        self.bullet = self.turret.get_bullets()\n",
    "\n",
    "    def _get_obs(self):\n",
    "\n",
    "        if len(self.bullet) == 1:\n",
    "            bullet_pos = self.bullet[0].pos\n",
    "        else:\n",
    "            bullet_pos = [0, 0]\n",
    "\n",
    "        # observation = {\n",
    "        #     \"predator_position\": self.predator_agent.current_position.tolist(),\n",
    "        #     \"bullet_position\": bullet_pos,  # get bullet position\n",
    "        #     \"target_position\": self.turret.position.tolist(),  # get the main target position\n",
    "        # }\n",
    "        # object_list = self.walls\n",
    "        # object_list.extend()\n",
    "        lengths, _ = self.cast_ray.cast_rays(self.predator_agent, self.walls)\n",
    "\n",
    "        observation = []\n",
    "        observation.extend(self.predator_agent.current_position.tolist())\n",
    "        observation.extend(bullet_pos)\n",
    "        observation.extend(self.turret.position.tolist())\n",
    "        observation.extend(lengths)\n",
    "        # print(f'observation:{observation}')\n",
    "        return observation\n",
    "\n",
    "    # def _get_info(self):\n",
    "    #     distance = 10000\n",
    "    #     self.goal_seen = is_ray_blocked(self.predator_agent.current_position, self.goal_coordinate, self.walls)\n",
    "    #     if self.goal_seen:\n",
    "    #         direction = self.goal_coordinate - self.predator_agent.current_position\n",
    "    #         distance = np.linalg.norm(direction)\n",
    "    #\n",
    "    #     info = {\n",
    "    #         \"goal_seen\": self.goal_seen,\n",
    "    #         \"distance\": distance,\n",
    "    #         \"vision_blocked\": not self.goal_seen,\n",
    "    #     }\n",
    "    #     # print(f'info: {info}')\n",
    "    #     return info\n",
    "\n",
    "    def get_reward(self, reward, done):\n",
    "        bullet_pos = 0\n",
    "        if len(self.bullet) == 1:\n",
    "            bullet_pos = self.bullet[0].pos\n",
    "        else:\n",
    "            bullet_pos = self.turret.position\n",
    "\n",
    "        if np.linalg.norm(np.abs(self.predator_agent.current_position - bullet_pos)) < self.predator_agent.radius + self.bullet[0].radius:\n",
    "            self.turret.destroy_bullet(self.bullet[0])\n",
    "            reward -= 50\n",
    "            done = True\n",
    "\n",
    "        if np.linalg.norm(np.abs(self.predator_agent.current_position - self.turret.position)) < self.predator_agent.radius + self.turret.radius + 20:\n",
    "            reward += 200\n",
    "            done = True\n",
    "\n",
    "        reward += 0.01\n",
    "\n",
    "        distance_between_targets = np.linalg.norm(np.abs(self.predator_agent.current_position - self.turret.position))\n",
    "        # print(10/distance_between_targets)\n",
    "        reward += (10/distance_between_targets)\n",
    "\n",
    "        return reward, done\n",
    "\n",
    "    def reset(self, seed=None, option=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.start_time = time.time()\n",
    "\n",
    "        self.wall.clear_walls()\n",
    "        self.walls = self.wall.make_wall(LEVEL_5_WALLS)\n",
    "\n",
    "        self.total_steps = 0\n",
    "        self.predator_total_reward = 0\n",
    "        self.animation_time = time.time()\n",
    "\n",
    "        # for predator in self.predator_agents:\n",
    "        self.predator_agent.agent_reset(width=self.screen_width, height=self.screen_height)\n",
    "        # self.predator_agent.movement_speed = 300\n",
    "        self.turret.rotate_turret(self.predator_agent.center)\n",
    "\n",
    "        # all the variable values inside the observation space needs to be sent inside the observation variable\n",
    "        # for this level purpose we decided to add the dictionary observation\n",
    "        # set the observation to a dictionary\n",
    "        observation = self._get_obs()\n",
    "        # info = self._get_info()\n",
    "\n",
    "        return observation, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        # initializing the return variables\n",
    "        done = False\n",
    "        reward = 0\n",
    "        truncated = False\n",
    "        info = {}\n",
    "        current_time = time.time()\n",
    "\n",
    "        current_animation_time = time.time()\n",
    "        difference_in_animaton_time = current_animation_time - self.animation_time\n",
    "        self.animation_time = current_animation_time\n",
    "        # print(difference_in_animaton_time * 300)\n",
    "        \n",
    "        elapsed_time = current_time - self.start_time\n",
    "\n",
    "        self.predator_agent.step_update(action, speed_factor=difference_in_animaton_time, range_x=self.screen_width, range_y=self.screen_height)\n",
    "        self.predator_agent = detect_collision(self.predator_agent, self.walls)\n",
    "\n",
    "        if len(self.turret.get_bullets()) == 0:\n",
    "            self.turret.shoot()\n",
    "\n",
    "        self.bullet[0].move(difference_in_animaton_time)\n",
    "        # if np.linalg.norm(np.abs(self.predator_agent.center - self.bullet[0].center)) < self.predator_agent.radius + self.bullet[0].radius:\n",
    "\n",
    "        # observation needs to be set a dictionary\n",
    "\n",
    "        self.total_steps += 1\n",
    "        reward, done = self.get_reward(reward, done)\n",
    "\n",
    "        if elapsed_time >= self.total_running_time:\n",
    "            reward -= 20\n",
    "            done = True\n",
    "\n",
    "        # getting observation and info\n",
    "        observation = self._get_obs()\n",
    "        # info = self._get_info()\n",
    "\n",
    "        self.predator_total_reward = reward\n",
    "        self.obs = observation\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "\n",
    "        return observation, reward, done, truncated, info\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode == 'rgb_array':\n",
    "            self._render_frame()\n",
    "\n",
    "    def _render_frame(self):\n",
    "        if self.window is None and self.render_mode == \"human\":\n",
    "            pygame.init()\n",
    "            pygame.display.init()\n",
    "            self.window = pygame.display.set_mode((self.screen_width, self.screen_height))\n",
    "            pygame.font.init()\n",
    "\n",
    "        if self.clock is None and self.render_mode == \"human\":\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "        screen = pygame.Surface((self.screen_width, self.screen_height))\n",
    "        screen.fill((249, 245, 246))\n",
    "\n",
    "        # for the predator\n",
    "        predator = self.predator_agent\n",
    "        predator_rect = pygame.draw.circle(screen, (223, 106, 106), predator.center, predator.radius)\n",
    "        # pygame.draw.line(screen, RED, predator.center, predator.draw_direction_end, 5)\n",
    "\n",
    "        # for cast rays\n",
    "        lengths, angles = self.cast_ray.cast_rays(predator, self.walls)\n",
    "\n",
    "        for a, l in zip(angles, lengths):\n",
    "            end_point = (int(predator.center[0] + l * math.cos(math.radians(a))),\n",
    "                        int(predator.center[1] + l * math.sin(math.radians(a))))\n",
    "\n",
    "            pygame.draw.line(screen, (223, 106, 106), predator.center, end_point)\n",
    "\n",
    "        # for turret\n",
    "        pygame.draw.circle(screen, (82, 82, 78), self.turret.center, self.turret.radius)\n",
    "        pygame.draw.line(screen, (82, 82, 78), self.turret.center, self.turret.rotate_turret(predator.center), 4)\n",
    "\n",
    "        \n",
    "        # for the bullet\n",
    "        if len(self.bullet) != 0:\n",
    "            bullet_rect = pygame.draw.circle(screen, (115, 147, 167), self.bullet[0].center, self.bullet[0].radius)\n",
    "            self.turret.auto_destroy()\n",
    "            for wall in self.walls:\n",
    "                if bullet_rect.colliderect(wall):\n",
    "                    self.turret.destroy_bullet(self.bullet[0])\n",
    "\n",
    "        for key, wall in LEVEL_5_WALLS.items():\n",
    "            pygame.draw.rect(screen, (71, 151, 177), (wall['x'], wall['y'], wall['width'], wall['height']))\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "\n",
    "            font = pygame.font.Font(None, 18)\n",
    "\n",
    "            text_surface = font.render(f\"Reward: {self.predator_total_reward: .5f} \", True, (0, 0, 0))\n",
    "\n",
    "            text_rect = text_surface.get_rect()\n",
    "\n",
    "            text_rect.center = (self.screen_width - 200, 10)\n",
    "\n",
    "            screen.blit(text_surface, text_rect)\n",
    "            self.window.blit(screen, screen.get_rect())\n",
    "            pygame.event.pump()\n",
    "            pygame.display.update()\n",
    "\n",
    "            # this part is to fix the fps of rendering\n",
    "            # self.clock.tick(self.metadata[\"render_fps\"])\n",
    "\n",
    "        else:\n",
    "            return np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(screen)), axes=(1, 0, 2)\n",
    "            )\n",
    "        \n",
    "\n",
    "    def close(self):\n",
    "        if self.window is not None:\n",
    "            pygame.display.quit()\n",
    "            pygame.font.quit()\n",
    "            pygame.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_angle = 0  # 65 degrees to the left\n",
    "end_angle = 350  # 65 degrees to the right\n",
    "angle_step = 10  # One ray every 10 degrees\n",
    "ray_angles = np.arange(start_angle, end_angle + angle_step, angle_step).tolist()\n",
    "ray_angles = [angle%360 for angle in ray_angles]\n",
    "\n",
    "len(ray_angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([800 for _ in range(42)], dtype=np.float32)\n",
    "len(arr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GameEnv('human')\n",
    "env.reset()\n",
    "\n",
    "done = False\n",
    "total_reward = 0\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, _, _ = env.step(action)\n",
    "    print(obs)\n",
    "    total_reward += reward\n",
    "\n",
    "env.close()\n",
    "print(env.total_steps)\n",
    "print(total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join('Training', 'Logs', 'Final_3')\n",
    "model_path = os.path.join('Training', 'Models', 'Final_3')\n",
    "best_save_path = os.path.join('Training', 'Models', 'Final_3', 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = CheckpointCallback(\n",
    "  save_freq=1000000,\n",
    "  save_path=model_path,\n",
    "  name_prefix=\"rl_model\",\n",
    "  save_replay_buffer=True,\n",
    "  save_vecnormalize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GameEnv('human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_neurons = 256\n",
    "policy_kwargs = dict(activation_fn=th.nn.ReLU, net_arch=dict(pi=[128, 128], vf=[128, 128]))\n",
    "net_arch = [dict(pi=[128, 128, 128, 128], vf=[128, 128, 128, 128])]\n",
    "new_arch = dict(net_arch=[number_of_neurons, number_of_neurons, number_of_neurons, number_of_neurons])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN('MlpPolicy', env, learning_rate=0.003, policy_kwargs=new_arch, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "model.learn(total_timesteps=50000000, callback=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = os.path.join('Training', 'Models', 'Final_3', 'rl_model_5642788_steps.zip')\n",
    "buffer_path = os.path.join('Training', 'Models', 'Final_3', 'rl_model_replay_buffer_5642788_steps.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN.load(load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_replay_buffer(buffer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reset ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "model.learn(total_timesteps=50000000, callback=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
